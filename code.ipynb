{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4f56a5b-09f6-4653-a89d-f5fcaec27ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-3.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting absl-py (from keras)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in e:\\coding_softwares\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in e:\\coding_softwares\\lib\\site-packages (from keras) (13.3.5)\n",
      "Collecting namex (from keras)\n",
      "  Downloading namex-0.0.7-py3-none-any.whl.metadata (246 bytes)\n",
      "Requirement already satisfied: h5py in e:\\coding_softwares\\lib\\site-packages (from keras) (3.9.0)\n",
      "Collecting optree (from keras)\n",
      "  Downloading optree-0.10.0-cp311-cp311-win_amd64.whl.metadata (46 kB)\n",
      "     ---------------------------------------- 0.0/46.1 kB ? eta -:--:--\n",
      "     -------- ------------------------------- 10.2/46.1 kB ? eta -:--:--\n",
      "     ---------------- --------------------- 20.5/46.1 kB 217.9 kB/s eta 0:00:01\n",
      "     ---------------- --------------------- 20.5/46.1 kB 217.9 kB/s eta 0:00:01\n",
      "     ------------------------- ------------ 30.7/46.1 kB 163.8 kB/s eta 0:00:01\n",
      "     ------------------------- ------------ 30.7/46.1 kB 163.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 46.1/46.1 kB 153.4 kB/s eta 0:00:00\n",
      "Collecting ml-dtypes (from keras)\n",
      "  Downloading ml_dtypes-0.3.2-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in e:\\coding_softwares\\lib\\site-packages (from optree->keras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in e:\\coding_softwares\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\coding_softwares\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\coding_softwares\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n",
      "Downloading keras-3.1.1-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.1 MB 660.6 kB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/1.1 MB 656.4 kB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/1.1 MB 653.6 kB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/1.1 MB 653.6 kB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/1.1 MB 653.6 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.1/1.1 MB 448.2 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.2/1.1 MB 458.0 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.1 MB 458.0 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.1 MB 458.0 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.1 MB 458.0 kB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.2/1.1 MB 405.0 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.3/1.1 MB 491.1 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.3/1.1 MB 491.1 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.3/1.1 MB 491.1 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.3/1.1 MB 491.1 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.3/1.1 MB 491.1 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.3/1.1 MB 491.1 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.4/1.1 MB 420.5 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.5/1.1 MB 531.2 kB/s eta 0:00:02\n",
      "   --------------------- ------------------ 0.6/1.1 MB 599.7 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.6/1.1 MB 599.7 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.6/1.1 MB 599.7 kB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.6/1.1 MB 533.5 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.7/1.1 MB 600.7 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 0.8/1.1 MB 637.8 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 0.9/1.1 MB 696.5 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.0/1.1 MB 735.4 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.0/1.1 MB 734.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.1/1.1 MB 759.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 746.1 kB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 112.6/133.7 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 133.7/133.7 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.3.2-cp311-cp311-win_amd64.whl (127 kB)\n",
      "   ---------------------------------------- 0.0/127.7 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 71.7/127.7 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 127.7/127.7 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.10.0-cp311-cp311-win_amd64.whl (221 kB)\n",
      "   ---------------------------------------- 0.0/221.8 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 92.2/221.8 kB 1.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 153.6/221.8 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 221.8/221.8 kB 1.9 MB/s eta 0:00:00\n",
      "Installing collected packages: namex, optree, ml-dtypes, absl-py, keras\n",
      "Successfully installed absl-py-2.1.0 keras-3.1.1 ml-dtypes-0.3.2 namex-0.0.7 optree-0.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e37add01-617d-4503-9531-a4a541a36afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b5241-aee7-4dae-b21c-a6027c5b78e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc112963-8457-4ed3-a479-50b8f735aaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d2f754c-7df9-42bc-a8af-1d6a842eaea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, GRU, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64225c50-84b0-44b7-b52a-b6c844fccf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('urdu-sentiment-corpus-v1.tsv', sep='\\t', header=None, names=['Tweet', 'Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eea2bc57-86b1-42e2-9431-72a889fe7462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tweet</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ٹویٹر کا خیال کیسے آیا ؟</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Class\n",
       "0                                              Tweet  Class\n",
       "1  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...      P\n",
       "2  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...      N\n",
       "3                           ٹویٹر کا خیال کیسے آیا ؟      O\n",
       "4  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...      P"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "22301d80-46ae-4145-8550-7bd164ccc659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet    0\n",
       "Class    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6f9397d-f8ce-4bcd-8ff5-aca99d2bc904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet    0\n",
       "Class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['Class'].isin(['P', 'N'])] \n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ae4e633-7eb3-4e20-8a3f-10ef297b535d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P' 'N']\n"
     ]
    }
   ],
   "source": [
    "data.shape\n",
    "print(data['Class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8854ea6-1932-4873-ad8e-1835321f8d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tweet', 'Class'], dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24eb766d-5a83-4956-bc8f-9c3dedda341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, stop_words):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "urdu_stopwords = ['کا', 'کی', 'ہے', 'میں',\"اور\", \"کے\", \"میں\", \"کی\", \"ہے\", \"یہ\", \"پر\", \"سے\", \"ہیں\", \"کو\",\"ہو\",\"وہ\", \"اس\", \"کا\", \"جو\", \"کر\", \"تھا\", \"تو\", \"ہوں\", \"گی\"]\n",
    "\n",
    "# Preprocess the dataset \n",
    "data['Preprocessed_Tweet'] = data['Tweet'].apply(lambda x: preprocess_text(x, urdu_stopwords))\n",
    "label_mapping = {'P': 1, 'N': 0}\n",
    "data['Class'] = data['Class'].map(label_mapping)\n",
    "texts = data['Preprocessed_Tweet'].values\n",
    "labels = data['Class'].values\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "max_sequence_length = max(len(x) for x in sequences)\n",
    "data_padded = pad_sequences(sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cd64ed14-7e60-4e1b-b7a5-5254551dbff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...  715 1822 1823]\n",
      " [   0    0    0 ...    2   60  217]\n",
      " [   0    0    0 ...  305  718 1038]\n",
      " ...\n",
      " [   0    0    0 ...  825 4991  648]\n",
      " [   0    0    0 ...  633  268  634]\n",
      " [   0    0    0 ...   65  503  712]]\n"
     ]
    }
   ],
   "source": [
    "print(data_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "833f5936-5317-4cdd-82e6-ab72df863a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, GRU, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "def create_model(model_type, num_layers, dropout_rate, vocab_size, max_sequence_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=128, input_shape=(max_sequence_length,)))\n",
    "    \n",
    "    if model_type == 'RNN':\n",
    "        for i in range(num_layers - 1):\n",
    "            model.add(SimpleRNN(128, return_sequences=True, dropout=dropout_rate))\n",
    "        model.add(SimpleRNN(128, dropout=dropout_rate))\n",
    "    elif model_type == 'GRU':\n",
    "        for i in range(num_layers - 1):\n",
    "            model.add(GRU(128, return_sequences=True, dropout=dropout_rate))\n",
    "        model.add(GRU(128, dropout=dropout_rate))\n",
    "    elif model_type == 'LSTM':\n",
    "        for i in range(num_layers - 1):\n",
    "            model.add(LSTM(128, return_sequences=True, dropout=dropout_rate))\n",
    "        model.add(LSTM(128, dropout=dropout_rate))\n",
    "    elif model_type == 'BiLSTM':\n",
    "        for i in range(num_layers - 1):\n",
    "            model.add(Bidirectional(LSTM(128, return_sequences=True, dropout=dropout_rate)))\n",
    "        model.add(Bidirectional(LSTM(128, dropout=dropout_rate)))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c323497d-d112-4608-9a30-f2b8a2c38834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Coding_Softwares\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN with 2 layers and dropout rate of 0.3\n",
      "Epoch 1/10\n",
      "6/6 - 11s - 2s/step - accuracy: 0.5109 - loss: 0.7234 - val_accuracy: 0.5061 - val_loss: 0.6915\n",
      "Epoch 2/10\n",
      "6/6 - 1s - 91ms/step - accuracy: 0.7371 - loss: 0.5879 - val_accuracy: 0.5061 - val_loss: 0.7078\n",
      "Epoch 3/10\n",
      "6/6 - 1s - 91ms/step - accuracy: 0.8896 - loss: 0.3857 - val_accuracy: 0.5306 - val_loss: 0.8174\n",
      "Epoch 4/10\n",
      "6/6 - 1s - 91ms/step - accuracy: 0.9523 - loss: 0.1639 - val_accuracy: 0.5143 - val_loss: 1.0819\n",
      "Epoch 5/10\n",
      "6/6 - 1s - 91ms/step - accuracy: 0.9605 - loss: 0.0852 - val_accuracy: 0.5224 - val_loss: 1.2086\n",
      "Epoch 6/10\n",
      "6/6 - 1s - 92ms/step - accuracy: 0.9891 - loss: 0.0423 - val_accuracy: 0.5143 - val_loss: 1.2352\n",
      "Epoch 7/10\n",
      "6/6 - 1s - 89ms/step - accuracy: 0.9864 - loss: 0.0337 - val_accuracy: 0.5673 - val_loss: 1.1745\n",
      "Epoch 8/10\n",
      "6/6 - 1s - 90ms/step - accuracy: 0.9918 - loss: 0.0219 - val_accuracy: 0.5469 - val_loss: 1.2119\n",
      "Epoch 9/10\n",
      "6/6 - 1s - 84ms/step - accuracy: 0.9986 - loss: 0.0160 - val_accuracy: 0.5673 - val_loss: 1.2444\n",
      "Epoch 10/10\n",
      "6/6 - 0s - 82ms/step - accuracy: 0.9986 - loss: 0.0093 - val_accuracy: 0.5673 - val_loss: 1.2631\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step\n",
      "Training RNN with 2 layers and dropout rate of 0.7\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Coding_Softwares\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 - 11s - 2s/step - accuracy: 0.4973 - loss: 0.7433 - val_accuracy: 0.4694 - val_loss: 0.8326\n",
      "Epoch 2/10\n",
      "6/6 - 1s - 98ms/step - accuracy: 0.5436 - loss: 0.7062 - val_accuracy: 0.5510 - val_loss: 0.6899\n",
      "Epoch 3/10\n",
      "6/6 - 1s - 93ms/step - accuracy: 0.5804 - loss: 0.6812 - val_accuracy: 0.4857 - val_loss: 0.7018\n",
      "Epoch 4/10\n",
      "6/6 - 1s - 94ms/step - accuracy: 0.6076 - loss: 0.6476 - val_accuracy: 0.5592 - val_loss: 0.6880\n",
      "Epoch 5/10\n",
      "6/6 - 1s - 98ms/step - accuracy: 0.7030 - loss: 0.5937 - val_accuracy: 0.5265 - val_loss: 0.7238\n",
      "Epoch 6/10\n",
      "6/6 - 1s - 90ms/step - accuracy: 0.7943 - loss: 0.4724 - val_accuracy: 0.5184 - val_loss: 0.7580\n",
      "Epoch 7/10\n",
      "6/6 - 1s - 93ms/step - accuracy: 0.8542 - loss: 0.3352 - val_accuracy: 0.5388 - val_loss: 0.9470\n",
      "Epoch 8/10\n",
      "6/6 - 1s - 94ms/step - accuracy: 0.8937 - loss: 0.2656 - val_accuracy: 0.5224 - val_loss: 0.9754\n",
      "Epoch 9/10\n",
      "6/6 - 1s - 110ms/step - accuracy: 0.9223 - loss: 0.1939 - val_accuracy: 0.5265 - val_loss: 1.0857\n",
      "Epoch 10/10\n",
      "6/6 - 1s - 91ms/step - accuracy: 0.9373 - loss: 0.1505 - val_accuracy: 0.5265 - val_loss: 1.0779\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000216D50F4220> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Coding_Softwares\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN with 3 layers and dropout rate of 0.3\n",
      "Epoch 1/10\n",
      "6/6 - 14s - 2s/step - accuracy: 0.4850 - loss: 0.7938 - val_accuracy: 0.4531 - val_loss: 0.7193\n",
      "Epoch 2/10\n",
      "6/6 - 1s - 123ms/step - accuracy: 0.5232 - loss: 0.7005 - val_accuracy: 0.5306 - val_loss: 0.7025\n",
      "Epoch 3/10\n",
      "6/6 - 1s - 124ms/step - accuracy: 0.6608 - loss: 0.6262 - val_accuracy: 0.4857 - val_loss: 0.7025\n",
      "Epoch 4/10\n",
      "6/6 - 1s - 119ms/step - accuracy: 0.8379 - loss: 0.4626 - val_accuracy: 0.5102 - val_loss: 0.7891\n",
      "Epoch 5/10\n",
      "6/6 - 1s - 120ms/step - accuracy: 0.9428 - loss: 0.2092 - val_accuracy: 0.4898 - val_loss: 1.1504\n",
      "Epoch 6/10\n",
      "6/6 - 1s - 114ms/step - accuracy: 0.9659 - loss: 0.0829 - val_accuracy: 0.4857 - val_loss: 1.5302\n",
      "Epoch 7/10\n",
      "6/6 - 1s - 113ms/step - accuracy: 0.9891 - loss: 0.0471 - val_accuracy: 0.4980 - val_loss: 1.7070\n",
      "Epoch 8/10\n",
      "6/6 - 1s - 115ms/step - accuracy: 0.9932 - loss: 0.0289 - val_accuracy: 0.5061 - val_loss: 1.5983\n",
      "Epoch 9/10\n",
      "6/6 - 1s - 118ms/step - accuracy: 0.9986 - loss: 0.0146 - val_accuracy: 0.5102 - val_loss: 1.6795\n",
      "Epoch 10/10\n",
      "6/6 - 1s - 117ms/step - accuracy: 0.9932 - loss: 0.0129 - val_accuracy: 0.5102 - val_loss: 1.7220\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000216C8B7F740> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step\n",
      "Training RNN with 3 layers and dropout rate of 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Coding_Softwares\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 - 16s - 3s/step - accuracy: 0.5123 - loss: 0.7674 - val_accuracy: 0.4612 - val_loss: 0.7380\n",
      "Epoch 2/10\n",
      "6/6 - 1s - 128ms/step - accuracy: 0.4973 - loss: 0.7922 - val_accuracy: 0.5306 - val_loss: 0.7070\n",
      "Epoch 3/10\n",
      "6/6 - 1s - 130ms/step - accuracy: 0.4932 - loss: 0.7523 - val_accuracy: 0.5061 - val_loss: 0.6890\n",
      "Epoch 4/10\n",
      "6/6 - 1s - 127ms/step - accuracy: 0.4905 - loss: 0.7427 - val_accuracy: 0.5306 - val_loss: 0.7019\n",
      "Epoch 5/10\n",
      "6/6 - 1s - 128ms/step - accuracy: 0.4932 - loss: 0.7363 - val_accuracy: 0.5020 - val_loss: 0.6946\n",
      "Epoch 6/10\n",
      "6/6 - 1s - 130ms/step - accuracy: 0.5218 - loss: 0.7184 - val_accuracy: 0.5224 - val_loss: 0.6947\n",
      "Epoch 7/10\n",
      "6/6 - 1s - 130ms/step - accuracy: 0.5068 - loss: 0.7088 - val_accuracy: 0.5143 - val_loss: 0.6914\n",
      "Epoch 8/10\n",
      "6/6 - 1s - 129ms/step - accuracy: 0.4932 - loss: 0.7192 - val_accuracy: 0.4694 - val_loss: 0.7103\n",
      "Epoch 9/10\n",
      "6/6 - 1s - 126ms/step - accuracy: 0.5245 - loss: 0.7121 - val_accuracy: 0.4816 - val_loss: 0.6968\n",
      "Epoch 10/10\n",
      "6/6 - 1s - 129ms/step - accuracy: 0.5368 - loss: 0.6947 - val_accuracy: 0.5102 - val_loss: 0.6924\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step\n",
      "Training GRU with 2 layers and dropout rate of 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Coding_Softwares\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 - 16s - 3s/step - accuracy: 0.4986 - loss: 0.6937 - val_accuracy: 0.5143 - val_loss: 0.6924\n",
      "Epoch 2/10\n",
      "6/6 - 2s - 268ms/step - accuracy: 0.6362 - loss: 0.6849 - val_accuracy: 0.5714 - val_loss: 0.6892\n",
      "Epoch 3/10\n",
      "6/6 - 1s - 247ms/step - accuracy: 0.8011 - loss: 0.6486 - val_accuracy: 0.5714 - val_loss: 0.6826\n",
      "Epoch 4/10\n",
      "6/6 - 2s - 252ms/step - accuracy: 0.8774 - loss: 0.4732 - val_accuracy: 0.5878 - val_loss: 0.7187\n",
      "Epoch 5/10\n",
      "6/6 - 2s - 256ms/step - accuracy: 0.8651 - loss: 0.3037 - val_accuracy: 0.5796 - val_loss: 0.7771\n",
      "Epoch 6/10\n",
      "6/6 - 1s - 248ms/step - accuracy: 0.9619 - loss: 0.1740 - val_accuracy: 0.5959 - val_loss: 0.7093\n",
      "Epoch 7/10\n",
      "6/6 - 1s - 244ms/step - accuracy: 0.9823 - loss: 0.0979 - val_accuracy: 0.6122 - val_loss: 0.8292\n",
      "Epoch 8/10\n",
      "6/6 - 1s - 244ms/step - accuracy: 0.9918 - loss: 0.0379 - val_accuracy: 0.6286 - val_loss: 1.0211\n",
      "Epoch 9/10\n",
      "6/6 - 1s - 236ms/step - accuracy: 0.9932 - loss: 0.0159 - val_accuracy: 0.6163 - val_loss: 1.2592\n",
      "Epoch 10/10\n",
      "6/6 - 2s - 254ms/step - accuracy: 0.9959 - loss: 0.0110 - val_accuracy: 0.5959 - val_loss: 1.4504\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 201ms/step\n",
      "Training GRU with 2 layers and dropout rate of 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Coding_Softwares\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 - 15s - 3s/step - accuracy: 0.4850 - loss: 0.6935 - val_accuracy: 0.5265 - val_loss: 0.6929\n",
      "Epoch 2/10\n",
      "6/6 - 2s - 272ms/step - accuracy: 0.5286 - loss: 0.6916 - val_accuracy: 0.5306 - val_loss: 0.6914\n",
      "Epoch 3/10\n",
      "6/6 - 1s - 243ms/step - accuracy: 0.5845 - loss: 0.6862 - val_accuracy: 0.5633 - val_loss: 0.6907\n",
      "Epoch 4/10\n",
      "6/6 - 1s - 240ms/step - accuracy: 0.6744 - loss: 0.6748 - val_accuracy: 0.5592 - val_loss: 0.6867\n",
      "Epoch 5/10\n",
      "6/6 - 1s - 242ms/step - accuracy: 0.7561 - loss: 0.6245 - val_accuracy: 0.5673 - val_loss: 0.6821\n",
      "Epoch 6/10\n",
      "6/6 - 1s - 242ms/step - accuracy: 0.7711 - loss: 0.5216 - val_accuracy: 0.5633 - val_loss: 0.6670\n",
      "Epoch 7/10\n",
      "6/6 - 2s - 250ms/step - accuracy: 0.8597 - loss: 0.3662 - val_accuracy: 0.5796 - val_loss: 0.7249\n",
      "Epoch 8/10\n",
      "6/6 - 1s - 247ms/step - accuracy: 0.9210 - loss: 0.2245 - val_accuracy: 0.5878 - val_loss: 0.8704\n",
      "Epoch 9/10\n",
      "6/6 - 1s - 240ms/step - accuracy: 0.9360 - loss: 0.1477 - val_accuracy: 0.6082 - val_loss: 1.0058\n",
      "Epoch 10/10\n",
      "6/6 - 2s - 263ms/step - accuracy: 0.9619 - loss: 0.0994 - val_accuracy: 0.6082 - val_loss: 1.2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step\n",
      "Training GRU with 3 layers and dropout rate of 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Coding_Softwares\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 - 22s - 4s/step - accuracy: 0.4728 - loss: 0.6936 - val_accuracy: 0.5143 - val_loss: 0.6927\n",
      "Epoch 2/10\n",
      "6/6 - 2s - 392ms/step - accuracy: 0.5940 - loss: 0.6887 - val_accuracy: 0.5388 - val_loss: 0.6901\n",
      "Epoch 3/10\n",
      "6/6 - 2s - 389ms/step - accuracy: 0.7371 - loss: 0.6396 - val_accuracy: 0.5673 - val_loss: 0.6770\n",
      "Epoch 4/10\n",
      "6/6 - 2s - 368ms/step - accuracy: 0.8420 - loss: 0.4364 - val_accuracy: 0.6082 - val_loss: 0.7988\n",
      "Epoch 5/10\n",
      "6/6 - 2s - 371ms/step - accuracy: 0.9441 - loss: 0.1800 - val_accuracy: 0.6245 - val_loss: 0.8424\n",
      "Epoch 6/10\n",
      "6/6 - 2s - 385ms/step - accuracy: 0.9796 - loss: 0.0833 - val_accuracy: 0.5592 - val_loss: 1.0891\n",
      "Epoch 7/10\n",
      "6/6 - 2s - 389ms/step - accuracy: 0.9837 - loss: 0.0454 - val_accuracy: 0.6041 - val_loss: 1.3554\n",
      "Epoch 8/10\n",
      "6/6 - 2s - 381ms/step - accuracy: 0.9946 - loss: 0.0146 - val_accuracy: 0.5755 - val_loss: 1.5901\n",
      "Epoch 9/10\n",
      "6/6 - 2s - 414ms/step - accuracy: 0.9959 - loss: 0.0169 - val_accuracy: 0.5673 - val_loss: 1.7673\n",
      "Epoch 10/10\n",
      "6/6 - 3s - 419ms/step - accuracy: 0.9946 - loss: 0.0096 - val_accuracy: 0.5673 - val_loss: 1.8673\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 252ms/step\n",
      "Training GRU with 3 layers and dropout rate of 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Coding_Softwares\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 - 23s - 4s/step - accuracy: 0.5041 - loss: 0.6939 - val_accuracy: 0.4694 - val_loss: 0.6935\n",
      "Epoch 2/10\n",
      "6/6 - 2s - 387ms/step - accuracy: 0.5123 - loss: 0.6924 - val_accuracy: 0.5347 - val_loss: 0.6922\n",
      "Epoch 3/10\n",
      "6/6 - 2s - 388ms/step - accuracy: 0.5204 - loss: 0.6908 - val_accuracy: 0.5143 - val_loss: 0.6926\n",
      "Epoch 4/10\n",
      "6/6 - 3s - 417ms/step - accuracy: 0.5463 - loss: 0.6893 - val_accuracy: 0.5347 - val_loss: 0.6907\n",
      "Epoch 5/10\n",
      "6/6 - 2s - 412ms/step - accuracy: 0.5722 - loss: 0.6833 - val_accuracy: 0.5755 - val_loss: 0.6890\n",
      "Epoch 6/10\n",
      "6/6 - 2s - 380ms/step - accuracy: 0.6390 - loss: 0.6626 - val_accuracy: 0.5551 - val_loss: 0.6842\n",
      "Epoch 7/10\n",
      "6/6 - 2s - 380ms/step - accuracy: 0.7112 - loss: 0.5947 - val_accuracy: 0.5714 - val_loss: 0.6877\n",
      "Epoch 8/10\n",
      "6/6 - 2s - 415ms/step - accuracy: 0.7970 - loss: 0.4751 - val_accuracy: 0.6122 - val_loss: 0.6752\n",
      "Epoch 9/10\n",
      "6/6 - 2s - 308ms/step - accuracy: 0.8760 - loss: 0.3282 - val_accuracy: 0.5959 - val_loss: 0.7392\n",
      "Epoch 10/10\n",
      "6/6 - 2s - 323ms/step - accuracy: 0.9128 - loss: 0.2453 - val_accuracy: 0.6000 - val_loss: 0.9228\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 215ms/step\n",
      "Training LSTM with 2 layers and dropout rate of 0.3\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Coding_Softwares\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 - 12s - 2s/step - accuracy: 0.4768 - loss: 0.6936 - val_accuracy: 0.5551 - val_loss: 0.6914\n",
      "Epoch 2/10\n",
      "6/6 - 1s - 223ms/step - accuracy: 0.6090 - loss: 0.6882 - val_accuracy: 0.5429 - val_loss: 0.6899\n",
      "Epoch 3/10\n",
      "6/6 - 1s - 216ms/step - accuracy: 0.7289 - loss: 0.6613 - val_accuracy: 0.6327 - val_loss: 0.6699\n",
      "Epoch 4/10\n",
      "6/6 - 1s - 222ms/step - accuracy: 0.7371 - loss: 0.5627 - val_accuracy: 0.5959 - val_loss: 0.6494\n",
      "Epoch 5/10\n",
      "6/6 - 1s - 217ms/step - accuracy: 0.9046 - loss: 0.3627 - val_accuracy: 0.6000 - val_loss: 0.7014\n",
      "Epoch 6/10\n",
      "6/6 - 1s - 217ms/step - accuracy: 0.9360 - loss: 0.1800 - val_accuracy: 0.6612 - val_loss: 0.7919\n",
      "Epoch 7/10\n",
      "6/6 - 1s - 229ms/step - accuracy: 0.9619 - loss: 0.1053 - val_accuracy: 0.6245 - val_loss: 0.8616\n",
      "Epoch 8/10\n",
      "6/6 - 1s - 211ms/step - accuracy: 0.9837 - loss: 0.0535 - val_accuracy: 0.6163 - val_loss: 1.0210\n",
      "Epoch 9/10\n",
      "6/6 - 1s - 225ms/step - accuracy: 0.9877 - loss: 0.0381 - val_accuracy: 0.6286 - val_loss: 1.1096\n",
      "Epoch 10/10\n",
      "6/6 - 1s - 225ms/step - accuracy: 0.9918 - loss: 0.0270 - val_accuracy: 0.6245 - val_loss: 1.2607\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step\n",
      "Training LSTM with 2 layers and dropout rate of 0.7\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Coding_Softwares\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 - 11s - 2s/step - accuracy: 0.5041 - loss: 0.6924 - val_accuracy: 0.5265 - val_loss: 0.6930\n",
      "Epoch 2/10\n",
      "6/6 - 1s - 234ms/step - accuracy: 0.5477 - loss: 0.6906 - val_accuracy: 0.5102 - val_loss: 0.6935\n",
      "Epoch 3/10\n",
      "6/6 - 1s - 222ms/step - accuracy: 0.5409 - loss: 0.6905 - val_accuracy: 0.5469 - val_loss: 0.6906\n",
      "Epoch 4/10\n",
      "6/6 - 1s - 231ms/step - accuracy: 0.5463 - loss: 0.6865 - val_accuracy: 0.5510 - val_loss: 0.6914\n",
      "Epoch 5/10\n",
      "6/6 - 1s - 231ms/step - accuracy: 0.6076 - loss: 0.6744 - val_accuracy: 0.5592 - val_loss: 0.6862\n",
      "Epoch 6/10\n",
      "6/6 - 1s - 228ms/step - accuracy: 0.6458 - loss: 0.6550 - val_accuracy: 0.5673 - val_loss: 0.6751\n",
      "Epoch 7/10\n",
      "6/6 - 1s - 222ms/step - accuracy: 0.7439 - loss: 0.5973 - val_accuracy: 0.6041 - val_loss: 0.6532\n",
      "Epoch 8/10\n",
      "6/6 - 1s - 226ms/step - accuracy: 0.8215 - loss: 0.4380 - val_accuracy: 0.5959 - val_loss: 0.6558\n",
      "Epoch 9/10\n",
      "6/6 - 1s - 222ms/step - accuracy: 0.8733 - loss: 0.3136 - val_accuracy: 0.6163 - val_loss: 0.7166\n",
      "Epoch 10/10\n",
      "6/6 - 1s - 225ms/step - accuracy: 0.8924 - loss: 0.2818 - val_accuracy: 0.5796 - val_loss: 0.7678\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step\n",
      "Training LSTM with 3 layers and dropout rate of 0.3\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Coding_Softwares\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 - 16s - 3s/step - accuracy: 0.4796 - loss: 0.6947 - val_accuracy: 0.4612 - val_loss: 0.6941\n",
      "Epoch 2/10\n",
      "6/6 - 2s - 405ms/step - accuracy: 0.5490 - loss: 0.6921 - val_accuracy: 0.5265 - val_loss: 0.6926\n",
      "Epoch 3/10\n",
      "6/6 - 2s - 358ms/step - accuracy: 0.6526 - loss: 0.6880 - val_accuracy: 0.5347 - val_loss: 0.6922\n",
      "Epoch 4/10\n",
      "6/6 - 3s - 422ms/step - accuracy: 0.6757 - loss: 0.6540 - val_accuracy: 0.5102 - val_loss: 0.7563\n",
      "Epoch 5/10\n",
      "6/6 - 2s - 368ms/step - accuracy: 0.7234 - loss: 0.5787 - val_accuracy: 0.5510 - val_loss: 0.6858\n",
      "Epoch 6/10\n",
      "6/6 - 2s - 382ms/step - accuracy: 0.8174 - loss: 0.4374 - val_accuracy: 0.6000 - val_loss: 0.6638\n",
      "Epoch 7/10\n",
      "6/6 - 2s - 397ms/step - accuracy: 0.9469 - loss: 0.2125 - val_accuracy: 0.6327 - val_loss: 0.8902\n",
      "Epoch 8/10\n",
      "6/6 - 3s - 418ms/step - accuracy: 0.9619 - loss: 0.1100 - val_accuracy: 0.5959 - val_loss: 1.0344\n",
      "Epoch 9/10\n",
      "6/6 - 2s - 393ms/step - accuracy: 0.9796 - loss: 0.0627 - val_accuracy: 0.5837 - val_loss: 1.3029\n",
      "Epoch 10/10\n",
      "6/6 - 3s - 418ms/step - accuracy: 0.9823 - loss: 0.0411 - val_accuracy: 0.5878 - val_loss: 1.5367\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 199ms/step\n",
      "Training LSTM with 3 layers and dropout rate of 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Coding_Softwares\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 - 16s - 3s/step - accuracy: 0.4605 - loss: 0.6944 - val_accuracy: 0.4612 - val_loss: 0.6937\n",
      "Epoch 2/10\n",
      "6/6 - 2s - 369ms/step - accuracy: 0.4632 - loss: 0.6956 - val_accuracy: 0.5306 - val_loss: 0.6933\n",
      "Epoch 3/10\n",
      "6/6 - 2s - 388ms/step - accuracy: 0.5177 - loss: 0.6935 - val_accuracy: 0.5306 - val_loss: 0.6926\n",
      "Epoch 4/10\n",
      "6/6 - 2s - 349ms/step - accuracy: 0.5286 - loss: 0.6912 - val_accuracy: 0.5306 - val_loss: 0.6921\n",
      "Epoch 5/10\n",
      "6/6 - 2s - 369ms/step - accuracy: 0.5436 - loss: 0.6899 - val_accuracy: 0.5429 - val_loss: 0.6920\n",
      "Epoch 6/10\n",
      "6/6 - 2s - 350ms/step - accuracy: 0.5490 - loss: 0.6889 - val_accuracy: 0.5224 - val_loss: 0.6926\n",
      "Epoch 7/10\n",
      "6/6 - 2s - 350ms/step - accuracy: 0.5926 - loss: 0.6825 - val_accuracy: 0.5673 - val_loss: 0.6881\n",
      "Epoch 8/10\n",
      "6/6 - 2s - 345ms/step - accuracy: 0.6812 - loss: 0.6552 - val_accuracy: 0.5347 - val_loss: 0.6857\n",
      "Epoch 9/10\n",
      "6/6 - 2s - 377ms/step - accuracy: 0.7166 - loss: 0.5853 - val_accuracy: 0.6041 - val_loss: 0.6558\n",
      "Epoch 10/10\n",
      "6/6 - 2s - 378ms/step - accuracy: 0.8283 - loss: 0.4356 - val_accuracy: 0.5959 - val_loss: 0.7944\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 271ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Coding_Softwares\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BiLSTM with 2 layers and dropout rate of 0.3\n",
      "Epoch 1/10\n",
      "6/6 - 22s - 4s/step - accuracy: 0.4700 - loss: 0.6946 - val_accuracy: 0.4694 - val_loss: 0.6933\n",
      "Epoch 2/10\n",
      "6/6 - 3s - 504ms/step - accuracy: 0.5531 - loss: 0.6902 - val_accuracy: 0.5714 - val_loss: 0.6910\n",
      "Epoch 3/10\n",
      "6/6 - 3s - 514ms/step - accuracy: 0.7466 - loss: 0.6699 - val_accuracy: 0.5837 - val_loss: 0.6788\n",
      "Epoch 4/10\n",
      "6/6 - 3s - 545ms/step - accuracy: 0.8106 - loss: 0.5376 - val_accuracy: 0.5755 - val_loss: 0.7372\n",
      "Epoch 5/10\n",
      "6/6 - 3s - 558ms/step - accuracy: 0.9155 - loss: 0.2287 - val_accuracy: 0.6571 - val_loss: 0.9024\n",
      "Epoch 6/10\n",
      "6/6 - 5s - 810ms/step - accuracy: 0.9755 - loss: 0.0937 - val_accuracy: 0.6449 - val_loss: 1.2279\n",
      "Epoch 7/10\n",
      "6/6 - 3s - 489ms/step - accuracy: 0.9932 - loss: 0.0332 - val_accuracy: 0.6571 - val_loss: 1.2921\n",
      "Epoch 8/10\n",
      "6/6 - 3s - 471ms/step - accuracy: 0.9959 - loss: 0.0172 - val_accuracy: 0.6449 - val_loss: 1.8154\n",
      "Epoch 9/10\n",
      "6/6 - 3s - 520ms/step - accuracy: 0.9973 - loss: 0.0144 - val_accuracy: 0.6408 - val_loss: 1.9464\n",
      "Epoch 10/10\n",
      "6/6 - 3s - 477ms/step - accuracy: 0.9973 - loss: 0.0158 - val_accuracy: 0.6531 - val_loss: 1.8574\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 381ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Coding_Softwares\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BiLSTM with 2 layers and dropout rate of 0.7\n",
      "Epoch 1/10\n",
      "6/6 - 21s - 4s/step - accuracy: 0.4578 - loss: 0.6976 - val_accuracy: 0.4694 - val_loss: 0.6955\n",
      "Epoch 2/10\n",
      "6/6 - 3s - 564ms/step - accuracy: 0.5286 - loss: 0.6906 - val_accuracy: 0.5306 - val_loss: 0.6917\n",
      "Epoch 3/10\n",
      "6/6 - 4s - 598ms/step - accuracy: 0.5136 - loss: 0.6928 - val_accuracy: 0.5388 - val_loss: 0.6909\n",
      "Epoch 4/10\n",
      "6/6 - 3s - 470ms/step - accuracy: 0.5681 - loss: 0.6855 - val_accuracy: 0.5143 - val_loss: 0.6920\n",
      "Epoch 5/10\n",
      "6/6 - 3s - 444ms/step - accuracy: 0.6458 - loss: 0.6687 - val_accuracy: 0.5837 - val_loss: 0.6805\n",
      "Epoch 6/10\n",
      "6/6 - 3s - 448ms/step - accuracy: 0.6839 - loss: 0.6156 - val_accuracy: 0.5796 - val_loss: 0.6671\n",
      "Epoch 7/10\n",
      "6/6 - 3s - 451ms/step - accuracy: 0.8406 - loss: 0.4205 - val_accuracy: 0.6327 - val_loss: 0.8494\n",
      "Epoch 8/10\n",
      "6/6 - 3s - 473ms/step - accuracy: 0.9169 - loss: 0.2114 - val_accuracy: 0.5918 - val_loss: 1.0364\n",
      "Epoch 9/10\n",
      "6/6 - 3s - 482ms/step - accuracy: 0.9537 - loss: 0.1418 - val_accuracy: 0.6490 - val_loss: 0.9485\n",
      "Epoch 10/10\n",
      "6/6 - 3s - 494ms/step - accuracy: 0.9605 - loss: 0.1104 - val_accuracy: 0.6204 - val_loss: 0.8909\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 307ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Coding_Softwares\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BiLSTM with 3 layers and dropout rate of 0.3\n",
      "Epoch 1/10\n",
      "6/6 - 30s - 5s/step - accuracy: 0.4905 - loss: 0.6940 - val_accuracy: 0.4653 - val_loss: 0.6951\n",
      "Epoch 2/10\n",
      "6/6 - 5s - 833ms/step - accuracy: 0.5341 - loss: 0.6912 - val_accuracy: 0.5551 - val_loss: 0.6909\n",
      "Epoch 3/10\n",
      "6/6 - 5s - 783ms/step - accuracy: 0.6281 - loss: 0.6737 - val_accuracy: 0.6000 - val_loss: 0.6791\n",
      "Epoch 4/10\n",
      "6/6 - 5s - 769ms/step - accuracy: 0.8065 - loss: 0.5664 - val_accuracy: 0.6327 - val_loss: 0.6893\n",
      "Epoch 5/10\n",
      "6/6 - 5s - 800ms/step - accuracy: 0.9278 - loss: 0.2480 - val_accuracy: 0.6449 - val_loss: 0.9401\n",
      "Epoch 6/10\n",
      "6/6 - 5s - 835ms/step - accuracy: 0.9714 - loss: 0.0867 - val_accuracy: 0.6245 - val_loss: 1.4653\n",
      "Epoch 7/10\n",
      "6/6 - 5s - 752ms/step - accuracy: 0.9809 - loss: 0.0632 - val_accuracy: 0.6449 - val_loss: 1.6797\n",
      "Epoch 8/10\n",
      "6/6 - 5s - 796ms/step - accuracy: 0.9946 - loss: 0.0260 - val_accuracy: 0.6245 - val_loss: 1.6168\n",
      "Epoch 9/10\n",
      "6/6 - 5s - 850ms/step - accuracy: 0.9986 - loss: 0.0111 - val_accuracy: 0.6000 - val_loss: 1.6750\n",
      "Epoch 10/10\n",
      "6/6 - 5s - 805ms/step - accuracy: 0.9946 - loss: 0.0172 - val_accuracy: 0.6245 - val_loss: 1.7714\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 419ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Coding_Softwares\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BiLSTM with 3 layers and dropout rate of 0.7\n",
      "Epoch 1/10\n",
      "6/6 - 31s - 5s/step - accuracy: 0.4986 - loss: 0.6940 - val_accuracy: 0.4653 - val_loss: 0.6942\n",
      "Epoch 2/10\n",
      "6/6 - 5s - 843ms/step - accuracy: 0.5014 - loss: 0.6938 - val_accuracy: 0.4735 - val_loss: 0.6932\n",
      "Epoch 3/10\n",
      "6/6 - 5s - 858ms/step - accuracy: 0.5123 - loss: 0.6967 - val_accuracy: 0.5306 - val_loss: 0.6918\n",
      "Epoch 4/10\n",
      "6/6 - 5s - 847ms/step - accuracy: 0.5136 - loss: 0.6934 - val_accuracy: 0.5347 - val_loss: 0.6911\n",
      "Epoch 5/10\n",
      "6/6 - 5s - 874ms/step - accuracy: 0.5572 - loss: 0.6848 - val_accuracy: 0.5592 - val_loss: 0.6908\n",
      "Epoch 6/10\n",
      "6/6 - 10s - 2s/step - accuracy: 0.5504 - loss: 0.6840 - val_accuracy: 0.6082 - val_loss: 0.6864\n",
      "Epoch 7/10\n",
      "6/6 - 5s - 833ms/step - accuracy: 0.6390 - loss: 0.6586 - val_accuracy: 0.5265 - val_loss: 0.6785\n",
      "Epoch 8/10\n",
      "6/6 - 5s - 901ms/step - accuracy: 0.7834 - loss: 0.4801 - val_accuracy: 0.5429 - val_loss: 1.0577\n",
      "Epoch 9/10\n",
      "6/6 - 5s - 883ms/step - accuracy: 0.8610 - loss: 0.3574 - val_accuracy: 0.5837 - val_loss: 0.9747\n",
      "Epoch 10/10\n",
      "6/6 - 5s - 890ms/step - accuracy: 0.8951 - loss: 0.2926 - val_accuracy: 0.6286 - val_loss: 0.9294\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 500ms/step\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_sequence_length = max(len(x) for x in data_padded)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_padded, labels, test_size=0.25, random_state=42)\n",
    "model_types = ['RNN', 'GRU', 'LSTM', 'BiLSTM']\n",
    "num_layers_options = [2, 3]\n",
    "dropout_rate_options = [0.3, 0.7]\n",
    "results = []\n",
    "\n",
    "for model_type in model_types:\n",
    "    for num_layers in num_layers_options:\n",
    "        for dropout_rate in dropout_rate_options:\n",
    "            model = create_model(model_type, num_layers, dropout_rate, vocab_size, max_sequence_length)\n",
    "            print(f\"Training {model_type} with {num_layers} layers and dropout rate of {dropout_rate}\")\n",
    "            history = model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test), verbose=2)\n",
    "            \n",
    "            # Evaluation\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_classes = np.round(y_pred).astype(int)\n",
    "            report = classification_report(y_test, y_pred_classes, target_names=['Negative', 'Positive'], output_dict=True)\n",
    "            accuracy = report['accuracy']\n",
    "            \n",
    "            # Save results\n",
    "            results.append({\n",
    "                'Model Type': model_type,\n",
    "                'Number of Layers': num_layers,\n",
    "                'Dropout Rate': dropout_rate,\n",
    "                'Accuracy': accuracy,\n",
    "                'Precision (Positive)': report['Positive']['precision'],\n",
    "                'Recall (Positive)': report['Positive']['recall'],\n",
    "                'F1-Score (Positive)': report['Positive']['f1-score']\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc546634-44fd-493f-9a71-e4d5504817f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ffbb5923-99b2-4fa9-b179-610d23b32eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Number of Layers</th>\n",
       "      <th>Dropout Rate</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (Positive)</th>\n",
       "      <th>Recall (Positive)</th>\n",
       "      <th>F1-Score (Positive)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.567347</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.469565</td>\n",
       "      <td>0.504673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.526531</td>\n",
       "      <td>0.496241</td>\n",
       "      <td>0.573913</td>\n",
       "      <td>0.532258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RNN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.478992</td>\n",
       "      <td>0.495652</td>\n",
       "      <td>0.487179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RNN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRU</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.595918</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.556522</td>\n",
       "      <td>0.563877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GRU</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.608163</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.495652</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GRU</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.567347</td>\n",
       "      <td>0.537815</td>\n",
       "      <td>0.556522</td>\n",
       "      <td>0.547009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GRU</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.558621</td>\n",
       "      <td>0.704348</td>\n",
       "      <td>0.623077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.624490</td>\n",
       "      <td>0.587786</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.626016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.579592</td>\n",
       "      <td>0.538961</td>\n",
       "      <td>0.721739</td>\n",
       "      <td>0.617100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.587755</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.634783</td>\n",
       "      <td>0.591093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.595918</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.713043</td>\n",
       "      <td>0.623574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>0.582609</td>\n",
       "      <td>0.611872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.620408</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.597403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.624490</td>\n",
       "      <td>0.587786</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.626016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.452174</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Type  Number of Layers  Dropout Rate  Accuracy  Precision (Positive)  \\\n",
       "0         RNN                 2           0.3  0.567347              0.545455   \n",
       "1         RNN                 2           0.7  0.526531              0.496241   \n",
       "2         RNN                 3           0.3  0.510204              0.478992   \n",
       "3         RNN                 3           0.7  0.510204              0.461538   \n",
       "4         GRU                 2           0.3  0.595918              0.571429   \n",
       "5         GRU                 2           0.7  0.608163              0.600000   \n",
       "6         GRU                 3           0.3  0.567347              0.537815   \n",
       "7         GRU                 3           0.7  0.600000              0.558621   \n",
       "8        LSTM                 2           0.3  0.624490              0.587786   \n",
       "9        LSTM                 2           0.7  0.579592              0.538961   \n",
       "10       LSTM                 3           0.3  0.587755              0.553030   \n",
       "11       LSTM                 3           0.7  0.595918              0.554054   \n",
       "12     BiLSTM                 2           0.3  0.653061              0.644231   \n",
       "13     BiLSTM                 2           0.7  0.620408              0.594828   \n",
       "14     BiLSTM                 3           0.3  0.624490              0.587786   \n",
       "15     BiLSTM                 3           0.7  0.628571              0.650000   \n",
       "\n",
       "    Recall (Positive)  F1-Score (Positive)  \n",
       "0            0.469565             0.504673  \n",
       "1            0.573913             0.532258  \n",
       "2            0.495652             0.487179  \n",
       "3            0.260870             0.333333  \n",
       "4            0.556522             0.563877  \n",
       "5            0.495652             0.542857  \n",
       "6            0.556522             0.547009  \n",
       "7            0.704348             0.623077  \n",
       "8            0.669565             0.626016  \n",
       "9            0.721739             0.617100  \n",
       "10           0.634783             0.591093  \n",
       "11           0.713043             0.623574  \n",
       "12           0.582609             0.611872  \n",
       "13           0.600000             0.597403  \n",
       "14           0.669565             0.626016  \n",
       "15           0.452174             0.533333  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f4d31-8769-4846-88f2-eeb05275f92d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
